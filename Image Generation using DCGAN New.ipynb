{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UsRYmICgD7-_"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers import (Dense, Dropout, Flatten, BatchNormalization,\n",
        "                                     Conv2D, Conv2DTranspose, Reshape, LeakyReLU, Input)\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.metrics import Mean\n",
        "from tensorflow.keras.losses import BinaryCrossentropy\n",
        "from tensorflow.keras.layers import Layer\n",
        "import pathlib\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "# Set dataset path\n",
        "root_path = pathlib.Path(\"animefacedataset/images\")\n",
        "\n",
        "# Data Augmentation: Introduce minor transformations for better generalization\n",
        "data_augmentation = keras.Sequential([\n",
        "    keras.layers.RandomFlip(\"horizontal\"),\n",
        "    keras.layers.RandomRotation(0.1),\n",
        "    keras.layers.RandomZoom(0.1),\n",
        "])\n",
        "\n",
        "# Load dataset and apply data augmentation\n",
        "batch_size = 32\n",
        "data = keras.utils.image_dataset_from_directory(\n",
        "    directory=root_path,\n",
        "    label_mode=None,  # No labels for GAN\n",
        "    batch_size=batch_size,\n",
        "    image_size=(64, 64)\n",
        ").map(lambda x: data_augmentation((x - 127.5) / 127.5))  # Normalize images to [-1, 1]\n",
        "\n",
        "def plot_images(images, title):\n",
        "    plt.figure(figsize=(6, 6))\n",
        "    for i in range(9):\n",
        "        ax = plt.subplot(3, 3, i + 1)\n",
        "        plt.imshow((images[i] * 127.5 + 127.5).numpy().astype(\"uint8\"))  # Convert back to [0, 255]\n",
        "        plt.axis(\"off\")\n",
        "    plt.suptitle(title)\n",
        "    plt.show()\n",
        "\n",
        "sample_images = next(iter(data))\n",
        "plot_images(sample_images, \"Sample Anime Faces\")\n",
        "\n",
        "class SpectralNormalization(Layer):\n",
        "    def __init__(self, layer):\n",
        "        super(SpectralNormalization, self).__init__()\n",
        "        self.layer = layer\n",
        "\n",
        "    def call(self, inputs):\n",
        "        weights = self.layer.kernel\n",
        "        sigma = tf.linalg.norm(weights, ord=2)  # Compute spectral norm\n",
        "        self.layer.kernel = weights / sigma  # Normalize weights\n",
        "        return self.layer(inputs)\n",
        "\n",
        "def build_generator(latent_dim):\n",
        "    model = Sequential([\n",
        "        Dense(4 * 4 * 256, input_shape=(latent_dim,), use_bias=False),\n",
        "        Reshape((4, 4, 256)),\n",
        "        BatchNormalization(),\n",
        "        LeakyReLU(),\n",
        "\n",
        "        Conv2DTranspose(128, (4, 4), strides=2, padding='same', use_bias=False),\n",
        "        BatchNormalization(),\n",
        "        LeakyReLU(),\n",
        "\n",
        "        Conv2DTranspose(128, (4, 4), strides=2, padding='same', use_bias=False),\n",
        "        BatchNormalization(),\n",
        "        LeakyReLU(),\n",
        "\n",
        "        Conv2DTranspose(64, (4, 4), strides=2, padding='same', use_bias=False),\n",
        "        BatchNormalization(),\n",
        "        LeakyReLU(),\n",
        "\n",
        "        Conv2DTranspose(3, (4, 4), strides=2, padding='same', activation='tanh')\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "G_model = build_generator(latent_dim=100)\n",
        "\n",
        "def build_discriminator():\n",
        "    inputs = Input(shape=(64, 64, 3))\n",
        "    x = SpectralNormalization(Conv2D(64, (3, 3), strides=2, padding='same'))(inputs)\n",
        "    x = LeakyReLU(0.2)(x)\n",
        "    x = Dropout(0.3)(x)\n",
        "\n",
        "    x = SpectralNormalization(Conv2D(128, (3, 3), strides=2, padding='same'))(x)\n",
        "    x = LeakyReLU(0.2)(x)\n",
        "    x = Dropout(0.3)(x)\n",
        "\n",
        "    x = SpectralNormalization(Conv2D(256, (3, 3), strides=2, padding='same'))(x)\n",
        "    x = LeakyReLU(0.2)(x)\n",
        "    x = Dropout(0.3)(x)\n",
        "\n",
        "    x = Flatten()(x)\n",
        "    outputs = Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "    return Model(inputs, outputs)\n",
        "\n",
        "D_model = build_discriminator()\n",
        "\n",
        "class GAN(tf.keras.Model):\n",
        "    def __init__(self, generator, discriminator, latent_dim):\n",
        "        super(GAN, self).__init__()\n",
        "        self.generator = generator\n",
        "        self.discriminator = discriminator\n",
        "        self.latent_dim = latent_dim\n",
        "        self.g_loss_metric = Mean(name=\"g_loss\")\n",
        "        self.d_loss_metric = Mean(name=\"d_loss\")\n",
        "\n",
        "    def compile(self, g_optimizer, d_optimizer, loss_fn):\n",
        "        super(GAN, self).compile()\n",
        "        self.g_optimizer = g_optimizer\n",
        "        self.d_optimizer = d_optimizer\n",
        "        self.loss_fn = loss_fn\n",
        "\n",
        "    @property\n",
        "    def metrics(self):\n",
        "        return [self.g_loss_metric, self.d_loss_metric]\n",
        "\n",
        "    def train_step(self, real_images):\n",
        "        batch_size = tf.shape(real_images)[0]\n",
        "        random_latent_vectors = tf.random.normal((batch_size, self.latent_dim))\n",
        "        fake_images = self.generator(random_latent_vectors)\n",
        "\n",
        "        combined_images = tf.concat([real_images, fake_images], axis=0)\n",
        "        labels = tf.concat([tf.ones((batch_size, 1)), tf.zeros((batch_size, 1))], axis=0)\n",
        "        labels += 0.05 * tf.random.uniform(tf.shape(labels))  # Label smoothing\n",
        "\n",
        "        with tf.GradientTape() as d_tape:\n",
        "            d_predictions = self.discriminator(combined_images)\n",
        "            d_loss = self.loss_fn(labels, d_predictions)\n",
        "\n",
        "        d_grads = d_tape.gradient(d_loss, self.discriminator.trainable_weights)\n",
        "        self.d_optimizer.apply_gradients(zip(d_grads, self.discriminator.trainable_weights))\n",
        "\n",
        "        misleading_labels = tf.ones((batch_size, 1))\n",
        "        with tf.GradientTape() as g_tape:\n",
        "            g_predictions = self.discriminator(self.generator(random_latent_vectors))\n",
        "            g_loss = self.loss_fn(misleading_labels, g_predictions)\n",
        "\n",
        "        g_grads = g_tape.gradient(g_loss, self.generator.trainable_weights)\n",
        "        self.g_optimizer.apply_gradients(zip(g_grads, self.generator.trainable_weights))\n",
        "\n",
        "        self.d_loss_metric.update_state(d_loss)\n",
        "        self.g_loss_metric.update_state(g_loss)\n",
        "\n",
        "        return {\"d_loss\": self.d_loss_metric.result(), \"g_loss\": self.g_loss_metric.result()}\n",
        "\n",
        "gan = GAN(G_model, D_model, latent_dim=100)\n",
        "gan.compile(g_optimizer=Adam(2e-4, beta_1=0.5), d_optimizer=Adam(1e-4, beta_1=0.5), loss_fn=BinaryCrossentropy())\n",
        "\n",
        "epochs = 50\n",
        "history = gan.fit(data, epochs=epochs)\n",
        "\n",
        "noise = tf.random.normal([16, 100])\n",
        "generated_images = G_model(noise, training=False)\n",
        "plot_images(generated_images, \"Generated Anime Faces\")\n",
        "\n",
        "import tensorflow_hub as hub\n",
        "\n",
        "# Load the pretrained InceptionV3 model\n",
        "inception_model = hub.load('https://tfhub.dev/google/imagenet/inception_v3/classification/5')\n",
        "\n",
        "def calculate_inception_score(images):\n",
        "    # Resize images to (299, 299) as required by InceptionV3\n",
        "    images = tf.image.resize(images, (299, 299))\n",
        "    images = (images + 1.0) / 2.0  # Scale to [0, 1]\n",
        "    preds = inception_model(images)\n",
        "    p_yx = tf.nn.softmax(preds)\n",
        "    p_y = tf.reduce_mean(p_yx, axis=0)\n",
        "\n",
        "    kl_div = tf.reduce_sum(p_yx * (tf.math.log(p_yx) - tf.math.log(p_y)), axis=1)\n",
        "    return tf.exp(tf.reduce_mean(kl_div))\n",
        "\n",
        "def calculate_fid(real_images, generated_images):\n",
        "    real_images_resized = tf.image.resize(real_images, (299, 299))\n",
        "    fake_images_resized = tf.image.resize(generated_images, (299, 299))\n",
        "\n",
        "    real_features = inception_model(real_images_resized)\n",
        "    fake_features = inception_model(fake_images_resized)\n",
        "\n",
        "    real_mu, real_sigma = tf.nn.moments(real_features, axes=[0])\n",
        "    fake_mu, fake_sigma = tf.nn.moments(fake_features, axes=[0])\n",
        "\n",
        "    diff = real_mu - fake_mu\n",
        "    fid = tf.reduce_sum(diff**2) + tf.trace(real_sigma + fake_sigma - 2 * tf.linalg.sqrtm(real_sigma @ fake_sigma))\n",
        "    return fid\n",
        "\n",
        "# Example: Calculate Inception Score and FID for generated images\n",
        "sample_generated_images = G_model(tf.random.normal([32, 100]), training=False)\n",
        "is_score = calculate_inception_score(sample_generated_images)\n",
        "fid_score = calculate_fid(sample_images, sample_generated_images)\n",
        "\n",
        "print(f\"Inception Score: {is_score.numpy()}, FID: {fid_score.numpy()}\")\n",
        "\n",
        "G_model.save(\"generator_model.h5\")\n",
        "D_model.save(\"discriminator_model.h5\")\n",
        "\n",
        "loaded_G_model = keras.models.load_model(\"generator_model.h5\")\n",
        "loaded_D_model = keras.models.load_model(\"discriminator_model.h5\")\n",
        "\n",
        "from keras_tuner import RandomSearch\n",
        "\n",
        "def build_gan_model(hp):\n",
        "    latent_dim = hp.Int(\"latent_dim\", min_value=50, max_value=200, step=50)\n",
        "    g_lr = hp.Choice(\"g_lr\", values=[1e-4, 2e-4, 5e-4])\n",
        "    d_lr = hp.Choice(\"d_lr\", values=[1e-5, 1e-4, 1e-3])\n",
        "\n",
        "    G_model = build_generator(latent_dim)\n",
        "    D_model = build_discriminator()\n",
        "\n",
        "    gan = GAN(G_model, D_model, latent_dim)\n",
        "    gan.compile(\n",
        "        g_optimizer=Adam(g_lr, beta_1=0.5),\n",
        "        d_optimizer=Adam(d_lr, beta_1=0.5),\n",
        "        loss_fn=BinaryCrossentropy(),\n",
        "    )\n",
        "    return gan\n",
        "\n",
        "tuner = RandomSearch(\n",
        "    build_gan_model,\n",
        "    objective=\"val_loss\",\n",
        "    max_trials=5,\n",
        "    executions_per_trial=1,\n",
        "    directory=\"gan_tuning\",\n",
        "    project_name=\"anime_gan\"\n",
        ")\n",
        "\n",
        "tuner.search(data, epochs=5, validation_data=data.take(1))\n",
        "best_model = tuner.get_best_models(1)[0]\n",
        "\n",
        "checkpoint_cb = keras.callbacks.ModelCheckpoint(\n",
        "    \"best_model.h5\", save_best_only=True\n",
        ")\n",
        "early_stopping_cb = keras.callbacks.EarlyStopping(\n",
        "    patience=5, restore_best_weights=True\n",
        ")\n",
        "\n",
        "gan.fit(data, epochs=50, callbacks=[checkpoint_cb, early_stopping_cb])\n",
        "\n",
        "def generate_and_plot_images(generator, num_images=16):\n",
        "    noise = tf.random.normal([num_images, 100])\n",
        "    generated_images = generator(noise, training=False)\n",
        "    plot_images(generated_images, \"Generated Images\")\n",
        "\n",
        "generate_and_plot_images(G_model)\n",
        "\n",
        "def train_gan(gan, dataset, epochs=50):\n",
        "    for epoch in range(epochs):\n",
        "        print(f\"Epoch {epoch + 1}/{epochs}\")\n",
        "        start = time.time()\n",
        "\n",
        "        for real_images in dataset:\n",
        "            gan.train_step(real_images)\n",
        "\n",
        "        # Generate sample images after every epoch\n",
        "        generate_and_plot_images(gan.generator, 9)\n",
        "        print(f\"Time taken for epoch {epoch + 1}: {time.time() - start:.2f} sec\")\n",
        "\n",
        "train_gan(gan, data, epochs=50)"
      ]
    }
  ]
}